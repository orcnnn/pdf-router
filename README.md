# ğŸš€ PDF Router - AkÄ±llÄ± PDF Ä°ÅŸleme Sistemi

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)

**PDF sayfalarÄ±nÄ± iÃ§erik tÃ¼rÃ¼ne gÃ¶re otomatik sÄ±nÄ±flandÄ±rÄ±p, uygun AI modellerine yÃ¶nlendiren akÄ±llÄ± sistem**

[ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§) â€¢ [ğŸ“‹ Ã–zellikler](#-Ã¶zellikler) â€¢ [âš™ï¸ Kurulum](#ï¸-kurulum) â€¢ [ğŸ”§ KullanÄ±m](#-kullanÄ±m) â€¢ [ğŸ“Š Mimari](#-mimari)

</div>

---

## ğŸ¯ Proje HakkÄ±nda

PDF Router, PDF sayfalarÄ±nÄ± iÃ§erik tÃ¼rÃ¼ne gÃ¶re otomatik olarak sÄ±nÄ±flandÄ±rÄ±p, her iÃ§erik tÃ¼rÃ¼ iÃ§in en uygun AI modelini kullanarak iÅŸleyen akÄ±llÄ± bir sistemdir. Marker ve Qwen2.5-VL gibi farklÄ± AI modellerini kullanarak PDF iÃ§eriÄŸini optimize edilmiÅŸ ÅŸekilde iÅŸler.

### ğŸ”¥ Ana Ã–zellikler

- **ğŸ§  AkÄ±llÄ± SÄ±nÄ±flandÄ±rma**: PDF sayfalarÄ±nÄ± iÃ§erik tÃ¼rÃ¼ne gÃ¶re otomatik sÄ±nÄ±flandÄ±rÄ±r
- **ğŸ”„ Ã‡oklu Ä°ÅŸleme ModÃ¼lÃ¼**: Marker (tablo/soru/metin) ve Qwen2.5-VL (gÃ¶rsel iÃ§erik) desteÄŸi
- **âš–ï¸ Load Balancing**: Marker servisleri iÃ§in round-robin yÃ¼k dengeleme
- **ğŸŒŠ Streaming Ä°ÅŸleme**: BÃ¼yÃ¼k veri setlerini bellek dostu ÅŸekilde iÅŸler
- **ğŸ¤— Hugging Face Entegrasyonu**: SonuÃ§larÄ± otomatik olarak HF Hub'a yÃ¼kler
- **ğŸ›¡ï¸ Hata ToleransÄ±**: Robust hata yÃ¶netimi ve fallback mekanizmalarÄ±
- **ğŸ“Š DetaylÄ± Loglama**: Her aÅŸamada kapsamlÄ± debug Ã§Ä±ktÄ±larÄ±

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1ï¸âƒ£ Repository'yi KlonlayÄ±n
```bash
git clone <repository-url>
cd pdf-router
```

### 2ï¸âƒ£ Gerekli Paketleri YÃ¼kleyin
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Environment DeÄŸiÅŸkenlerini AyarlayÄ±n
```bash
# .env dosyasÄ± oluÅŸturun
echo "HF_TOKEN=your_huggingface_token" >> .env
echo "VLLM_API_URL=http://localhost:8000" >> .env
echo "VLLM_API_KEY=your_api_key" >> .env
```

### 4ï¸âƒ£ Servisleri BaÅŸlatÄ±n
```bash
# TÃ¼m servisleri otomatik baÅŸlat (Ã¶nerilen)
sh run_job.sh

# Veya manuel olarak
sh start_marker_1.sh    # Marker servisleri
sh start_vllm_server.sh # vLLM servisi
python main.py run.yaml # Ana iÅŸlem
```

---

## ğŸ“‹ Sistem Gereksinimleri

### ğŸ’» DonanÄ±m
- **GPU**: CUDA destekli (Ã¶nerilen: 8GB+ VRAM)
- **RAM**: En az 16GB (Ã¶nerilen: 32GB+)
- **Disk**: Yeterli alan (geÃ§ici dosyalar iÃ§in)

### ğŸ YazÄ±lÄ±m
- **Python**: 3.8+
- **CUDA**: 11.8+ (GPU iÃ§in)
- **Slurm**: Cluster ortamÄ± iÃ§in

### ğŸ“¦ Ana BaÄŸÄ±mlÄ±lÄ±klar
```
datasets>=2.14.0
vllm>=0.2.0
openai>=1.0.0
requests>=2.28.0
loguru>=0.7.0
PIL>=9.0.0
```

---

## âš™ï¸ KonfigÃ¼rasyon

### ğŸ“„ `run.yaml` DosyasÄ±
```yaml
# Model ve Veri Seti
model_name: "Qwen/Qwen2.5-VL-32B-Instruct"
ds_name: "orcn/predictions"                    # GiriÅŸ veri seti
output_ds_name: "sghosts/orcun_processed"      # Ã‡Ä±kÄ±ÅŸ veri seti

# Ä°ÅŸleme SeÃ§enekleri
use_vlm: false                                 # HTTP client kullan
use_marker: true                               # Marker kullan
debug: true                                    # Debug modu

# Streaming ve Performans
streaming: true                                # Streaming modu
skip_existing: false                           # Mevcut split'leri atla
push_mode: overwrite                           # Ã‡Ä±kÄ±ÅŸ modu
limit: 10                                      # Test iÃ§in limit

# GPU AyarlarÄ±
tensor_parallel_size: 4                        # GPU sayÄ±sÄ±
gpu_memory_utilization: 0.8                    # GPU bellek kullanÄ±mÄ±
max_model_len: 32000                           # Maksimum model uzunluÄŸu
```

---

## ğŸ”§ KullanÄ±m

### ğŸ¯ Temel KullanÄ±m
```bash
python main.py run.yaml
```

### ğŸš€ TÃ¼m Servisleri BaÅŸlatma
```bash
sh run_job.sh
```

### ğŸ”§ Manuel Servis YÃ¶netimi
```bash
# Marker servisleri
sh start_marker_1.sh

# vLLM servisi (Slurm)
sh start_vllm_server.sh

# Ana iÅŸlem
python main.py run.yaml
```

### ğŸ“Š GeliÅŸmiÅŸ SeÃ§enekler
```bash
# Debug modu ile
python main.py run.yaml --debug

# Belirli split ile
python main.py run.yaml --start-from-split 0 --until-split 5

# Limit ile test
python main.py run.yaml --limit 100
```

---

## ğŸ“Š Mimari

### ğŸ—ï¸ Sistem Mimarisi
```mermaid
graph TB
    A[PDF SayfalarÄ±] --> B[Ä°Ã§erik SÄ±nÄ±flandÄ±rma]
    B --> C{Ä°Ã§erik TÃ¼rÃ¼?}
    C -->|Tablo/Soru/Metin| D[Marker Ä°ÅŸleme]
    C -->|GÃ¶rsel/Resim| E[Qwen2.5-VL Ä°ÅŸleme]
    C -->|DiÄŸer| F[Atla]
    D --> G[Metin Post-Processing]
    E --> H[VLM Post-Processing]
    G --> I[Hugging Face Hub]
    H --> I
    
    subgraph "Load Balancer"
        J[Marker Server 1]
        K[Marker Server 2]
        L[Marker Server 3]
        M[Marker Server 4]
    end
    
    D --> J
    D --> K
    D --> L
    D --> M
```

### ğŸ·ï¸ Ä°Ã§erik SÄ±nÄ±flandÄ±rmasÄ±

| SÄ±nÄ±f | Ä°ÅŸleme ModÃ¼lÃ¼ | AÃ§Ä±klama | Confidence |
|-------|---------------|----------|------------|
| `Tablo` | Marker | Tablo iÃ§eriÄŸi | > 0.5 |
| `Soru` | Marker | Soru metinleri | > 0.5 |
| `Metin` | Marker | DÃ¼z metin iÃ§erik | > 0.5 |
| `Resim` | Qwen2.5-VL | GÃ¶rsel iÃ§erik | > 0.5 |
| `Resim/Tablo AÃ§Ä±klamasÄ±` | Qwen2.5-VL | GÃ¶rsel aÃ§Ä±klamalarÄ± | > 0.5 |
| `Kapak SayfasÄ±` | Qwen2.5-VL | Kapak sayfalarÄ± | > 0.5 |
| `Ä°Ã§indekiler` | Atla | Ä°Ã§indekiler sayfasÄ± | - |

---

## ğŸ”§ Marker KonfigÃ¼rasyonu

### ğŸ“‹ Marker Servisleri
```bash
# 4 farklÄ± portta Ã§alÄ±ÅŸan Marker servisleri
CUDA_VISIBLE_DEVICES=0 marker_server --port 8001
CUDA_VISIBLE_DEVICES=1 marker_server --port 8002
CUDA_VISIBLE_DEVICES=2 marker_server --port 8003
CUDA_VISIBLE_DEVICES=3 marker_server --port 8004
```

### ğŸ”„ Load Balancing
- **Round-robin** yÃ¼k dengeleme
- **Otomatik failover**
- **Thread-safe** implementasyon

### ğŸ“¤ Marker API Payload
```json
{
    "filepath": "/tmp/tmpbzniuzcs.png",
    "page_range": null,
    "languages": null,
    "force_ocr": true,
    "paginate_output": false,
    "output_format": "markdown"
}
```

---

## ğŸ“ Ã‡Ä±ktÄ± YapÄ±sÄ±

### ğŸ¤— Hugging Face Hub
- **Hedef**: `https://huggingface.co/datasets/sghosts/orcun_processed`
- **Format**: Hugging Face Datasets
- **Ä°Ã§erik**: Ä°ÅŸlenmiÅŸ metinler + metadata

### ğŸ“ Log DosyalarÄ±
```
logs/
â”œâ”€â”€ marker_server_1.log    # Port 8001
â”œâ”€â”€ marker_server_2.log    # Port 8002
â”œâ”€â”€ marker_server_3.log    # Port 8003
â”œâ”€â”€ marker_server_4.log    # Port 8004
â””â”€â”€ vllm_server_*.log      # vLLM servisi
```

### ğŸ“Š Ä°ÅŸleme ModlarÄ±

#### ğŸŒŠ Streaming Modu
```yaml
streaming: true
```
- âœ… BÃ¼yÃ¼k veri setlerini bellek dostu iÅŸler
- âœ… Her split bittiÄŸinde anÄ±nda yÃ¼kler
- âœ… RAM kullanÄ±mÄ±nÄ± optimize eder

#### ğŸ“¦ Batch Modu
```yaml
streaming: false
vlm_batch_size: 8
```
- âœ… TÃ¼m veriyi bellekte tutar
- âœ… Daha hÄ±zlÄ± iÅŸleme
- âœ… Daha fazla RAM gerektirir

#### ğŸ”„ Append Modu
```yaml
push_mode: append
```
- âœ… Mevcut verilerle birleÅŸtirir
- âœ… Duplicate kontrolÃ¼ yapar
- âœ… Incremental gÃ¼ncelleme

---

## ğŸ› ï¸ Hata AyÄ±klama

### ğŸ“Š Log KontrolÃ¼
```bash
# Marker servisleri
tail -f logs/marker_server_*.log

# vLLM servisi
tail -f logs/vllm_server_*.log

# Ana iÅŸlem
python main.py run.yaml 2>&1 | tee processing.log
```

### ğŸ” YaygÄ±n Sorunlar

#### 1. **Marker Servisleri BaÅŸlamÄ±yor**
```bash
# GPU bellek kontrolÃ¼
nvidia-smi

# Port Ã§akÄ±ÅŸmasÄ± kontrolÃ¼
netstat -tulpn | grep :800

# Marker loglarÄ±
cat logs/marker_server_*.log
```

#### 2. **vLLM BaÄŸlantÄ± HatasÄ±**
```bash
# API URL kontrolÃ¼
curl http://10.128.41.142:8000/v1/models

# Environment deÄŸiÅŸkenleri
echo $VLLM_API_URL
echo $VLLM_API_KEY
```

#### 3. **Hugging Face YÃ¼kleme HatasÄ±**
```bash
# Token kontrolÃ¼
echo $HF_TOKEN

# Ä°nternet baÄŸlantÄ±sÄ±
ping huggingface.co
```

#### 4. **Veri Seti YÃ¼klenmiyor**
```bash
# Veri seti kontrolÃ¼
python -c "import datasets; print(datasets.load_dataset('orcn/predictions', streaming=True))"

# Split kontrolÃ¼
python -c "import datasets; print(datasets.get_dataset_config_names('orcn/predictions'))"
```

---

## ğŸ“ˆ Performans Optimizasyonu

### ğŸ¯ GPU AyarlarÄ±
```yaml
tensor_parallel_size: 4        # GPU sayÄ±sÄ±na gÃ¶re ayarlayÄ±n
gpu_memory_utilization: 0.8    # Bellek kullanÄ±mÄ±nÄ± optimize edin
```

### ğŸ’¾ Bellek AyarlarÄ±
```yaml
vlm_batch_size: 8              # VLM batch boyutu
buffer_size: 256               # RAM buffer boyutu
```

### âš¡ Streaming vs Batch
- **Streaming**: BÃ¼yÃ¼k veri setleri iÃ§in (Ã¶nerilen)
- **Batch**: KÃ¼Ã§Ã¼k veri setleri iÃ§in

### ğŸ”§ Confidence Threshold
```python
# router.py
labels_list = [l for l in labels_list if float(l.get('confidence', 0.0)) > 0.5]
```

---

## ğŸ§ª Test ve GeliÅŸtirme

### ğŸš€ HÄ±zlÄ± Test
```bash
# Limit ile test
python main.py run.yaml --limit 10

# Debug modu ile
python main.py run.yaml --debug

# Belirli split ile
python main.py run.yaml --start-from-split 0 --until-split 1
```

### ğŸ”¬ Unit Testler
```bash
# Test Ã§alÄ±ÅŸtÄ±rma
python -m pytest tests/

# Coverage raporu
python -m pytest --cov=router tests/
```

### ğŸ“Š Benchmark
```bash
# Performans testi
python benchmark.py --samples 1000

# Memory profiling
python -m memory_profiler main.py run.yaml
```

---

## ğŸ¤ KatkÄ±da Bulunma

### ğŸ”€ GeliÅŸtirme SÃ¼reci
1. **Fork** yapÄ±n
2. **Feature branch** oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. **Commit** yapÄ±n (`git commit -m 'Add amazing feature'`)
4. **Push** yapÄ±n (`git push origin feature/amazing-feature`)
5. **Pull Request** oluÅŸturun

### ğŸ“ Kod StandartlarÄ±
- **PEP 8** Python kod standardÄ±
- **Type hints** kullanÄ±mÄ±
- **Docstring** zorunluluÄŸu
- **Unit test** coverage > 80%

### ğŸ› Bug Report
- **Issue** oluÅŸturun
- **Log dosyalarÄ±nÄ±** paylaÅŸÄ±n
- **Sistem konfigÃ¼rasyonunu** belirtin
- **Reproducible steps** saÄŸlayÄ±n

---

## ğŸ“„ Lisans

Bu proje **MIT lisansÄ±** altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

```
MIT License

Copyright (c) 2025 PDF Router

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

---

## ğŸ†˜ Destek ve Ä°letiÅŸim

### ğŸ“ Destek KanallarÄ±
- **GitHub Issues**: [Issues](https://github.com/your-repo/issues)
- **Discussions**: [Discussions](https://github.com/your-repo/discussions)
- **Email**: support@example.com

### ğŸ“š DokÃ¼mantasyon
- **API Reference**: [docs/api.md](docs/api.md)
- **Tutorials**: [docs/tutorials.md](docs/tutorials.md)
- **FAQ**: [docs/faq.md](docs/faq.md)

### ğŸŒŸ Topluluk
- **Discord**: [Join our Discord](https://discord.gg/your-server)
- **Twitter**: [@pdfrouter](https://twitter.com/pdfrouter)
- **LinkedIn**: [PDF Router](https://linkedin.com/company/pdf-router)

---

## ğŸ“š Referanslar

### ğŸ”— BaÄŸlantÄ±lar
- [Marker Documentation](https://github.com/VikParuchuri/marker)
- [vLLM Documentation](https://docs.vllm.ai/)
- [Qwen2.5-VL Model](https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct)
- [Hugging Face Datasets](https://huggingface.co/docs/datasets/)

### ğŸ“– Akademik Referanslar
- [Qwen2.5-VL Paper](https://arxiv.org/abs/2024.xxx)
- [Marker Paper](https://arxiv.org/abs/2024.xxx)
- [vLLM Paper](https://arxiv.org/abs/2024.xxx)

---

<div align="center">

**â­ Bu projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!**

[â¬†ï¸ BaÅŸa DÃ¶n](#-pdf-router---akÄ±llÄ±-pdf-iÅŸleme-sistemi)

</div>